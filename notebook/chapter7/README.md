# Chapter 7: Stochastic Processes

> **ì±… í˜ì´ì§€**: 198-233
> **í•µì‹¬ ì£¼ì œ**: ìƒ˜í”Œë§, Importance Sampling, Brownian Motion, Markov Chain, MCMC, Auto-regressive Models
> **KAIST Challenge ì—°ê²°**: Challenge 13 (Importance Sampling), Challenge 14 (Langevin Dynamics), Challenge 15 (MCMC)

---

## ğŸ“š ëª©ì°¨

1. [ì™œ í™•ë¥  ê³¼ì •ì¸ê°€?](#1-ì™œ-í™•ë¥ -ê³¼ì •ì¸ê°€)
2. [Exact Sampling](#2-exact-sampling)
3. [Importance Sampling](#3-importance-sampling)
4. [Brownian Motionê³¼ Diffusion](#4-brownian-motionê³¼-diffusion)
5. [Markov Chainê³¼ MCMC](#5-markov-chainê³¼-mcmc)
6. [Langevin Dynamics](#6-langevin-dynamics)
7. [Auto-regressive Models](#7-auto-regressive-models)
8. [Notebooks ê°€ì´ë“œ](#8-notebooks-ê°€ì´ë“œ)
9. [Generative AIì—ì„œì˜ ì‘ìš©](#9-generative-aiì—ì„œì˜-ì‘ìš©)

---

## 1. ì™œ í™•ë¥  ê³¼ì •ì¸ê°€?

### í™•ë¥  ë¶„í¬ì—ì„œ í™•ë¥  ê³¼ì •ìœ¼ë¡œ

> **ì±… ì›ë¬¸ (p.198):**
> "Stochastic processes provide the natural mathematical language for describing uncertainty... They are the backbone of sampling, inference, noise injection, model training, and generative mechanisms."

```
Chapter 5: í™•ë¥  ë¶„í¬
    "í•œ ì‹œì ì˜ ëœë¤ ë³€ìˆ˜"
    X ~ P(X)

Chapter 7: í™•ë¥  ê³¼ì •
    "ì‹œê°„ì— ë”°ë¼ ì§„í™”í•˜ëŠ” ëœë¤ ë³€ìˆ˜"
    X(t), t âˆˆ [0, T]
```

### Generative AIì—ì„œì˜ í•µì‹¬ ì—­í• 

| í™•ë¥  ê³¼ì • | ì‘ìš© |
|----------|------|
| **Markov Chain** | Token-by-token ìƒì„±, MCMC |
| **Brownian Motion** | Diffusion ëª¨ë¸ì˜ Forward Process |
| **Langevin Dynamics** | Score-based ìƒì„± |
| **Auto-regressive** | GPT, Transformer |

---

## 2. Exact Sampling

### Inverse Transform Sampling (ITS)

> **ì±… ì›ë¬¸ (p.199):**
> "Given U ~ Uniform(0,1), Fâ»Â¹(U) is an exact sample from that distribution."

```
ì•„ì´ë””ì–´:
    ê· ë“±ë¶„í¬ U ~ Uniform(0,1)
    CDFì˜ ì—­í•¨ìˆ˜ ì ìš©: X = Fâ»Â¹(U)
    â†’ XëŠ” ì›í•˜ëŠ” ë¶„í¬ë¥¼ ë”°ë¦„!

ì˜ˆ: ì§€ìˆ˜ë¶„í¬ ìƒ˜í”Œë§
    F(x) = 1 - e^(-Î»x)
    Fâ»Â¹(u) = -log(1-u)/Î»

    U ~ Uniform(0,1)
    X = -log(1-U)/Î» ~ Exponential(Î»)
```

### ì™œ 1Dì—ì„œë§Œ ê°€ëŠ¥í•œê°€?

```
1D: CDF F: â„ â†’ [0,1]ì€ ì—­ë³€í™˜ ê°€ëŠ¥

ë‹¤ì°¨ì›: CDF F: â„^d â†’ [0,1]
    ìŠ¤ì¹¼ë¼ í•˜ë‚˜ì—ì„œ dì°¨ì› ë²¡í„° ë³µì› ë¶ˆê°€!
```

### Chain Rule Sampling (ë‹¤ì°¨ì› í™•ì¥)

```
p(xâ‚, xâ‚‚, ..., xâ‚™) = p(xâ‚) Â· p(xâ‚‚|xâ‚) Â· p(xâ‚ƒ|xâ‚,xâ‚‚) Â· ...

ìˆœì°¨ì  ìƒ˜í”Œë§:
    1. xâ‚ ~ p(xâ‚)           â† ITS ì‚¬ìš©
    2. xâ‚‚ ~ p(xâ‚‚|xâ‚)        â† ITS ì‚¬ìš©
    3. xâ‚ƒ ~ p(xâ‚ƒ|xâ‚,xâ‚‚)     â† ITS ì‚¬ìš©
    ...

ì´ê²ƒì´ Auto-regressive ëª¨ë¸ì˜ ì›ë¦¬!
```

---

## 3. Importance Sampling

### ë¬¸ì œ: ë³µì¡í•œ ë¶„í¬ì—ì„œì˜ ê¸°ëŒ“ê°’ ê³„ì‚°

$$\mathbb{E}_{p}[f(x)] = \int f(x) p(x) dx$$

"p(x)ì—ì„œ ìƒ˜í”Œë§ì´ ì–´ë µë‹¤ë©´?"

### í•´ê²°ì±…: ë‹¤ë¥¸ ë¶„í¬ q(x) ì‚¬ìš©

> **ì±… ì›ë¬¸ (p.203):**
> "Importance Sampling provides a principled way to compute expectations with respect to a target distribution p(x) by drawing samples from a simpler proposal distribution q(x)."

$$\mathbb{E}_p[f(x)] = \mathbb{E}_q\left[f(x) \cdot \frac{p(x)}{q(x)}\right]$$

```
IS ì¶”ì •ëŸ‰:
    E_p[f(x)] â‰ˆ (1/N) Î£áµ¢ w(xáµ¢) Â· f(xáµ¢)

    w(xáµ¢) = p(xáµ¢) / q(xáµ¢)  (ì¤‘ìš”ë„ ê°€ì¤‘ì¹˜)

ì¡°ê±´: q(x) > 0 wherever p(x) > 0
```

### ì˜ˆì‹œ: í¬ê·€ ì‚¬ê±´ í™•ë¥ 

ë…¸íŠ¸ë¶ `ImportanceSampling-RareEvent.ipynb`:

```
ëª©í‘œ: P(X > 3) ì¶”ì •, X ~ N(0,1)

ì§ì ‘ Monte Carlo:
    10âµê°œ ìƒ˜í”Œ ì¤‘ ~135ê°œë§Œ x > 3
    ë¶„ì‚° ë§¤ìš° í¼!

Importance Sampling:
    q(x) = N(3, 1)  â† 3 ê·¼ì²˜ì—ì„œ ë§ì´ ìƒ˜í”Œë§
    w(x) = p(x)/q(x)

    ë¶„ì‚° ëŒ€í­ ê°ì†Œ!
```

### Effective Sample Size (ESS)

```
ESS = (Î£áµ¢ wáµ¢)Â² / Î£áµ¢ wáµ¢Â²

ESSê°€ ë†’ìœ¼ë©´: íš¨ê³¼ì ì¸ proposal
ESSê°€ ë‚®ìœ¼ë©´: ê°€ì¤‘ì¹˜ê°€ ëª‡ ê°œì— ì§‘ì¤‘ â†’ ì¶”ì • ë¶ˆì•ˆì •
```

### Adaptive Importance Sampling

> **ì±… ì›ë¬¸ (p.207):**
> "Adaptive Importance Sampling aims to iteratively adapt the proposal distribution to better approximate the target."

Cross-Entropy Method:
1. ì´ˆê¸° proposal qâ‚€ ì„¤ì •
2. ìƒ˜í”Œë§, ê°€ì¤‘ì¹˜ ê³„ì‚°
3. ê°€ì¤‘ MLEë¡œ q ì—…ë°ì´íŠ¸
4. ë°˜ë³µ

---

## 4. Brownian Motionê³¼ Diffusion

### Brownian Motion ì •ì˜

> **ì±… ì›ë¬¸ (p.210):**
> "Brownian motion is the simplest nontrivial continuous-time stochastic process and serves as the universal scaling limit of random walks."

$$dW_t = \sqrt{dt} \cdot Z, \quad Z \sim \mathcal{N}(0, 1)$$

**í•µì‹¬ ì„±ì§ˆ**:
```
1. ì—°ì† ê²½ë¡œ: W(t)ëŠ” ì—°ì† í•¨ìˆ˜
2. ë…ë¦½ ì¦ë¶„: W(t+s) - W(s)ëŠ” W(t)ì™€ ë…ë¦½
3. ê°€ìš°ì‹œì•ˆ ì¦ë¶„: W(t) - W(s) ~ N(0, t-s)
4. W(0) = 0
```

### Heat Equationê³¼ì˜ ì—°ê²°

```
Brownian Motion:
    ì…ìê°€ ëœë¤í•˜ê²Œ í™•ì‚°

Heat Equation:
    âˆ‚u/âˆ‚t = (1/2) âˆ‚Â²u/âˆ‚xÂ²

ì—°ê²°:
    u(x, t) = E[f(W_t) | W_0 = x]
    "ì´ˆê¸° ì¡°ê±´ fì˜ í™•ì‚° = ì—´ ì „íŒŒ"
```

### SDE (Stochastic Differential Equation)

ì¼ë°˜ì ì¸ SDE:

$$dX_t = f(X_t, t) dt + g(X_t, t) dW_t$$

```
f(X, t): drift (ê²°ì •ë¡ ì  ë°©í–¥)
g(X, t): diffusion (í™•ë¥ ì  ë³€ë™)
dW_t: Brownian motion ì¦ë¶„
```

### Fokker-Planck Equation

SDEì˜ í™•ë¥  ë°€ë„ p(x, t) ì§„í™”:

$$\frac{\partial p}{\partial t} = -\frac{\partial}{\partial x}[f \cdot p] + \frac{1}{2}\frac{\partial^2}{\partial x^2}[g^2 \cdot p]$$

"ì…ìë“¤ì˜ ë¶„í¬ê°€ ì‹œê°„ì— ë”°ë¼ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ê°€?"

---

## 5. Markov Chainê³¼ MCMC

### Markov Chain

> **ì±… ì›ë¬¸ (p.220):**
> "A Markov chain is a sequence of random variables Xâ‚€, Xâ‚, Xâ‚‚, ... where the distribution of X_{n+1} depends only on X_n."

$$P(X_{n+1} | X_n, X_{n-1}, ..., X_0) = P(X_{n+1} | X_n)$$

"ë¯¸ë˜ëŠ” ê³¼ê±° ì „ì²´ê°€ ì•„ë‹Œ í˜„ì¬ì—ë§Œ ì˜ì¡´"

### ì •ìƒ ë¶„í¬ (Stationary Distribution)

$$\pi = \pi P$$

"ì¶©ë¶„íˆ ì˜¤ë˜ ëŒë¦¬ë©´, ì–´ë””ì„œ ì‹œì‘í•˜ë“  ë¶„í¬ê°€ Ï€ë¡œ ìˆ˜ë ´"

### MCMCì˜ ì•„ì´ë””ì–´

```
ëª©í‘œ: Ï€(x)ì—ì„œ ìƒ˜í”Œë§

ë¬¸ì œ: Ï€(x)ì—ì„œ ì§ì ‘ ìƒ˜í”Œë§ ì–´ë ¤ì›€

í•´ê²°: Ï€ë¥¼ ì •ìƒ ë¶„í¬ë¡œ ê°–ëŠ” Markov Chain ì„¤ê³„
      â†’ ì¶©ë¶„íˆ ì˜¤ë˜ ëŒë¦¬ë©´ Ï€ì—ì„œ ìƒ˜í”Œ!
```

### Metropolis-Hastings Algorithm

```python
def MH(x, T):
    for t in range(T):
        # 1. Proposal
        x_new = proposal(x)

        # 2. Acceptance probability
        Î± = min(1, Ï€(x_new) * q(x|x_new) / (Ï€(x) * q(x_new|x)))

        # 3. Accept/Reject
        if random() < Î±:
            x = x_new

    return x
```

### Detailed Balance

$$\pi(x) P(x \to y) = \pi(y) P(y \to x)$$

"xì—ì„œ yë¡œ ê°€ëŠ” í™•ë¥  íë¦„ = yì—ì„œ xë¡œ ì˜¤ëŠ” í™•ë¥  íë¦„"

â†’ ì´ê±¸ ë§Œì¡±í•˜ë©´ Ï€ê°€ ì •ìƒ ë¶„í¬!

---

## 6. Langevin Dynamics

### Overdamped Langevin Equation

> **ì±… ì›ë¬¸ (p.224):**

$$dX_t = -\nabla U(X_t) dt + \sqrt{2} dW_t$$

```
-âˆ‡U(X): ì—ë„ˆì§€ê°€ ë‚®ì€ ìª½ìœ¼ë¡œ ì´ë™ (gradient descent)
âˆš2 dW: ëœë¤í•œ íƒìƒ‰ (noise)

ê²°ê³¼: X_t â†’ Ï€(x) âˆ exp(-U(x)) ë¡œ ìˆ˜ë ´
```

### ì—ë„ˆì§€ ê¸°ë°˜ í•´ì„

```
ì—ë„ˆì§€: U(x)
ë¶„í¬: Ï€(x) âˆ exp(-U(x)/T)

ë‚®ì€ ì—ë„ˆì§€ = ë†’ì€ í™•ë¥ 

ì˜¨ë„ T:
    T â†’ 0: ìµœì†Œê°’ì—ë§Œ ì§‘ì¤‘
    T â†’ âˆ: ê· ë“± íƒìƒ‰
```

### Score Functionê³¼ì˜ ì—°ê²°

$$\nabla \log p(x) = -\nabla U(x)$$

```
Score = í™•ë¥ ì´ ì¦ê°€í•˜ëŠ” ë°©í–¥
      = ì—ë„ˆì§€ê°€ ê°ì†Œí•˜ëŠ” ë°©í–¥

Langevin Dynamics:
    dX = âˆ‡ log p(X) dt + âˆš2 dW
    "Score ë°©í–¥ìœ¼ë¡œ ì´ë™ + noise"
```

### Double Well ì˜ˆì‹œ

ë…¸íŠ¸ë¶ `Langevin-DoubleWell.ipynb`:

```
U(x) = (xÂ² - 1)Â² / 4

ë‘ ê°œì˜ well: x = Â±1

Langevinìœ¼ë¡œ ìƒ˜í”Œë§í•˜ë©´:
- ë‘ well ì‚¬ì´ë¥¼ ì™”ë‹¤ ê°”ë‹¤
- ê° wellì—ì„œ ë¨¸ë¬´ëŠ” ì‹œê°„ âˆ exp(-barrier height)
```

---

## 7. Auto-regressive Models

### Chain Rule ê¸°ë°˜ ìƒì„±

$$p(x_1, ..., x_n) = \prod_{i=1}^n p(x_i | x_1, ..., x_{i-1})$$

> **ì±… ì›ë¬¸ (p.227):**
> "This is precisely the mechanism underlying auto-regressive generative models."

```
í…ìŠ¤íŠ¸ ìƒì„±:
    p("The" "cat" "sat") = p("The") Ã— p("cat"|"The") Ã— p("sat"|"The cat")

ì´ë¯¸ì§€ ìƒì„±:
    p(í”½ì…€1, í”½ì…€2, ...) = p(í”½ì…€1) Ã— p(í”½ì…€2|í”½ì…€1) Ã— ...
```

### Markov Chainê³¼ì˜ ì°¨ì´

```
Markov Chain (ì°¨ìˆ˜ 1):
    p(x_n | x_{n-1}, ..., x_1) = p(x_n | x_{n-1})
    "ë°”ë¡œ ì´ì „ë§Œ ë´„"

Auto-regressive:
    p(x_n | x_{n-1}, ..., x_1)
    "ëª¨ë“  ì´ì „ì„ ë´„" â†’ ë” í‘œí˜„ë ¥ ë†’ìŒ

Transformer:
    Attentionìœ¼ë¡œ ëª¨ë“  ì´ì „ í† í° ì°¸ì¡° ê°€ëŠ¥!
```

---

## 8. Notebooks ê°€ì´ë“œ

### Stochastic/ í´ë”

| ë…¸íŠ¸ë¶ | ë­˜ ë°°ìš°ë‚˜? | í•µì‹¬ ì‹¤ìŠµ |
|--------|-----------|----------|
| `ITS-1D.ipynb` | Inverse Transform Sampling | 1D ìƒ˜í”Œë§ |
| `ChainRuleSampling-2D.ipynb` | Chain Rule ìƒ˜í”Œë§ | 2D ë¶„í¬ ìƒì„± |
| `ImportanceSampling-RareEvent.ipynb` | IS ê¸°ì´ˆ | í¬ê·€ ì‚¬ê±´ ì¶”ì • |
| `ImportanceSampling-GaussianPosterior.ipynb` | Bayesian IS | ì‚¬í›„ ë¶„í¬ ì¶”ì • |
| `AdaptiveIS-CE-fitGaussian.ipynb` | Adaptive IS | CE method |
| `AdaptiveIS-CE-rare-event.ipynb` | í¬ê·€ ì‚¬ê±´ + AIS | ê³ ê¸‰ ìƒ˜í”Œë§ |
| `BrownianMotion-and-HeatEquation.ipynb` | Brownian Motion | ì—´ ë°©ì •ì‹ ì—°ê²° |
| `Langevin-DoubleWell.ipynb` | Langevin Dynamics | ì—ë„ˆì§€ ê¸°ë°˜ ìƒ˜í”Œë§ |
| `RBM-MCMC.ipynb` | MCMC | Restricted Boltzmann Machine |

### ê¼­ í•´ë³¼ ì‹¤í—˜ë“¤

**1. Importance Sampling ë¶„ì‚°**
```python
# ImportanceSampling-RareEvent.ipynb
# ë‹¤ë¥¸ proposal q(x)ë¡œ ì‹¤í—˜
# ESS ë¹„êµ, ë¶„ì‚° ë¹„êµ
```

**2. Langevin ì˜¨ë„ íš¨ê³¼**
```python
# Langevin-DoubleWell.ipynb
# ì˜¨ë„ T: 0.1, 0.5, 1.0, 2.0
# ëª¨ë“œ ê°„ ì „ì´ ë¹ˆë„ ê´€ì°°
```

**3. Chain Rule ìˆœì„œ íš¨ê³¼**
```python
# ChainRuleSampling-2D.ipynb
# (xâ‚, xâ‚‚) vs (xâ‚‚, xâ‚) ìˆœì„œ
# ê²°ê³¼ ë¶„í¬ ë™ì¼í•œì§€ í™•ì¸
```

---

## 9. Generative AIì—ì„œì˜ ì‘ìš©

### Diffusion Model = SDE

```
Forward SDE (ë…¸ì´ì¦ˆ ì¶”ê°€):
    dX_t = f(X_t, t) dt + g(t) dW_t

Reverse SDE (ë””ë…¸ì´ì§•):
    dY_t = [f(Y_t, t) - g(t)Â² âˆ‡ log p(Y_t, t)] dt + g(t) dWÌ„_t

í•µì‹¬: Score âˆ‡ log p(x, t)ë¥¼ ì‹ ê²½ë§ìœ¼ë¡œ í•™ìŠµ!
```

### Score-Based Generative Models

```
í•™ìŠµ:
    Score network sÎ¸(x, t) â‰ˆ âˆ‡ log p(x, t)

ìƒì„±:
    Langevin dynamicsë¡œ ìƒ˜í”Œë§:
    x_{n+1} = x_n + Îµ Â· sÎ¸(x_n, t) + âˆš(2Îµ) Â· z
```

### Auto-regressive + Transformer = GPT

```
GPTì˜ ìƒì„±:
    1. <start> í† í°ìœ¼ë¡œ ì‹œì‘
    2. p(token_1 | <start>) ì—ì„œ ìƒ˜í”Œë§
    3. p(token_2 | <start>, token_1) ì—ì„œ ìƒ˜í”Œë§
    ...

Masked Self-Attention:
    ê° í† í°ì€ ì´ì „ í† í°ë“¤ë§Œ ì°¸ì¡° ê°€ëŠ¥
    â†’ Chain Rule êµ¬í˜„!
```

### Markov Chainê³¼ Token Generation

```
Top-k Sampling:
    í™•ë¥  ë†’ì€ kê°œ ì¤‘ì—ì„œ ì„ íƒ
    â†’ "ê²°ì •ë¡ ì " â†” "ë‹¤ì–‘ì„±" íŠ¸ë ˆì´ë“œì˜¤í”„

Temperature Scaling:
    p(token) âˆ exp(logit / T)

    T < 1: ë” ê²°ì •ë¡ ì  (ë†’ì€ í™•ë¥ ì— ì§‘ì¤‘)
    T > 1: ë” ë‹¤ì–‘í•¨ (ë¶„í¬ í‰í‰í•´ì§)
```

### MCMC in Energy-Based Models

```
Energy-Based Model:
    p(x) âˆ exp(-E_Î¸(x))

ìƒ˜í”Œë§:
    MCMC (Langevin, HMC ë“±) í•„ìš”
    â†’ ë¹„ìš©ì´ í¼, Diffusionë³´ë‹¤ ëŠë¦¼

ì¥ì :
    ëª¨ë¸ì´ explicit energy function
    ì´ìƒì¹˜ íƒì§€ ë“±ì— ìœ ìš©
```

---

## ğŸ“ í•µì‹¬ ì •ë¦¬

### ì´ ì±•í„°ì—ì„œ ê¼­ ê¸°ì–µí•  ê²ƒ

1. **Importance Sampling**
   - $w(x) = p(x)/q(x)$
   - ì¢‹ì€ proposal ì„ íƒì´ í•µì‹¬

2. **Brownian Motion**
   - ì—°ì† ì‹œê°„ ëœë¤ ì›Œí¬
   - Diffusionì˜ ê¸°ì´ˆ

3. **Langevin Dynamics**
   - $dX = -\nabla U(X) dt + \sqrt{2} dW$
   - Gradient + Noise â†’ Target ë¶„í¬ ìƒ˜í”Œë§

4. **MCMC**
   - Detailed Balance â†’ Stationary Distribution
   - ë³µì¡í•œ ë¶„í¬ì—ì„œ ìƒ˜í”Œë§

5. **Auto-regressive**
   - Chain Rule ë¶„í•´
   - GPT, Transformerì˜ ì›ë¦¬

---

## ğŸ”— ë‹¤ë¥¸ ì±•í„°ì™€ì˜ ì—°ê²°

| ì—°ê²° | ì„¤ëª… |
|------|------|
| **Ch.2 â†’ Ch.7** | ODE â†’ SDE (ë…¸ì´ì¦ˆ ì¶”ê°€) |
| **Ch.5 â†’ Ch.7** | í™•ë¥  ë¶„í¬ â†’ ì‹œê°„ì— ë”°ë¥¸ ì§„í™” |
| **Ch.6 â†’ Ch.7** | ì—”íŠ¸ë¡œí”¼ â†’ í™•ë¥  ê³¼ì •ì˜ ë³µì¡ë„ |
| **Ch.7 â†’ Ch.8** | MCMC â†’ Energy-Based Models |
| **Ch.7 â†’ Ch.9** | Langevin/SDE â†’ Diffusion Models |

---

*ì´ ë¬¸ì„œëŠ” Mathematics of Generative AI Book Chapter 7ì˜ í•™ìŠµ ê°€ì´ë“œì…ë‹ˆë‹¤.*
